{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YhKiNVyhKz0KKoypS1nglXDnCnOdXU86",
      "authorship_tag": "ABX9TyMWbbJ7g5iVnBD8wsoVTU5A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esther-pui/WOA7015-Assignment-3/blob/main/WOA7015_A3_Group.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main Objective:**\n",
        "build a **2-layer MLP** (a basic neural network) using **PyTorch** to **classify fetuses** based on a given dataset and **achieve a testing accuracy of up to 65%** by **finding the best settings** (hyperparameters)\n",
        "\n",
        "(!remove later)"
      ],
      "metadata": {
        "id": "yAxGphoCtF9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: Data prep (2%)**\n",
        "Input (16 dimensions) -> fully connected layer (10 hidden units) -> nonlinearity (ReLU)\n",
        "-> fully connected (5 hidden units) -> softmax\n",
        "\n",
        "\n",
        "1. Split data into 2 dataset (training, validation)\n",
        "2. Load 2 dataset (training shuffle=True)\n",
        "3. Set Batch Size in both DataLoader instance\n",
        "\n",
        "*scaling only do it on training data to prevent data leakage\n",
        "\n",
        "(!remove later)\n",
        "\n"
      ],
      "metadata": {
        "id": "iEF0oA1_vUlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive # remove later\n",
        "drive.mount('/content/drive') # remove later\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# train_file_path = '/Fetus_trainingdata.csv'\n",
        "# remove later\n",
        "train_file_path = '/content/drive/MyDrive/UM Master 2025/SEM 1 (2025 Oct)/WOA7015 ADVANCED MACHINE LEARNING (OCC4)/Assignment 3/Fetus_trainingdata.csv'\n",
        "\n",
        "try:\n",
        "  data = pd.read_csv(train_file_path)\n",
        "  print('\\nDrive load successfully!')\n",
        "\n",
        "except FileNotFoundError:\n",
        "  print(\"File not found, check your path on google drive.\")\n",
        "  exit()\n",
        "\n",
        "# first column = outcome\n",
        "x_features = data.iloc[:, 1:].copy()\n",
        "\n",
        "# second to last column are the features\n",
        "y_class = data.iloc[:, 0]\n",
        "\n",
        "# ===== 1(a) Instantiate two Datasets (2%) =====\n",
        "\n",
        "# convert into numerical code for CrossEntropyLoss\n",
        "y_numeric = y_class.astype('category').cat.codes.values\n",
        "num_classes = len(y_class.unique())\n",
        "\n",
        "# one-hot encoding of categorical variables\n",
        "x_features = pd.get_dummies(x_features, columns=['Ethnics'], prefix='Ethnics')\n",
        "# final input dimension for mlp\n",
        "input_dimension = x_features.shape[1]\n",
        "\n",
        "# split data: training size 80%, testing size 20%\n",
        "x_train_df, x_text_df, y_train_np, y_test_np = train_test_split(\n",
        "    x_features,\n",
        "    y_numeric,\n",
        "    test_size=0.2,\n",
        "    random_state=42, # ensure reproducible results\n",
        "    stratify=y_numeric # make sure proportion of classes is the same\n",
        ")\n",
        "\n",
        "# scaling\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train_df)\n",
        "x_test_scaled = scaler.transform(x_text_df)\n",
        "\n",
        "# datasets and dataloaders\n",
        "x_train_tensor = torch.tensor(x_train_scaled, dtype=torch.float32)\n",
        "x_test_tensor = torch.tensor(x_test_scaled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_np, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test_np, dtype=torch.long)\n",
        "\n",
        "# instantiate 2 datasets\n",
        "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
        "\n",
        "# instantiate 2 dataloaders\n",
        "BATCH_SIZE = 64\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True) #randomly reorder\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oykxqx8j5N12",
        "outputId": "298dd5af-21ac-4736-a0c3-6ab1d8036d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Drive load successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2: Building the 2-Layer MLP (2%)**\n",
        "define structure of neural network using Python class (torch.nn.Module)\n",
        "## Structure\n",
        "\n",
        "Input (16 dimensions) -> fully connected layer (10 hidden units) -> nonlinearity (ReLU) -> fully connected (5 hidden units) -> softmax\n",
        "\n",
        "\n",
        "1. Input Layer: Takes 16 features (16 dimensions)\n",
        "2. Hidden Layer 1: fully connected layer with 10 hidden units\n",
        "3. Activation: Apply ReLU non-linearity. Allows network learn complex patterns\n",
        "4. Hidden Layer 2:  Fully connected layer with 5 hidden units.\n",
        "5. Output Layer: Final layer have an output dimension equal to the number of classes in your fetus dataset\n",
        "\n",
        "## Methods\n",
        "\n",
        "*   __ init __ ( define the layers, e.g., torch.nn.Linear, torch.nn.ReLU)\n",
        "*   forward method (define how data flows through these layers)\n",
        "\n",
        "(!remove later)"
      ],
      "metadata": {
        "id": "2YxU73yFwZ9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 1(b) Instantiate your MLP class with init and forward methods (2%) =====\n",
        "\n",
        "# how many neurons each hidden layer has\n",
        "hidden_size1 = 10\n",
        "hidden_size2 = 5\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "  # archi: input -> linear(10) -> ReLU -> linear(5) -> ReLU -> logits(2)\n",
        "  def __init__(self, input_dim, h1_units, h2_units, output_dim):\n",
        "    super(MLP, self).__init__()\n",
        "\n",
        "    # fully connected (Linear) -> ReLU\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Linear(input_dim, h1_units),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    # fully connected (Linear) -> ReLU\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Linear(h1_units, h2_units),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.output_layer = nn.Linear(h2_units, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "\n",
        "    logits = self.output_layer(x)\n",
        "    return logits # raw, not probability scores (not softmax)\n",
        "\n",
        "# instantiate model\n",
        "model = MLP(input_dimension, hidden_size1, hidden_size2, num_classes)"
      ],
      "metadata": {
        "id": "J3GZtqLE7Y5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Training and Evaluation (2% + 4%)**\n",
        "\n",
        "## Training Loop and Loss Function\n",
        "1. Optimizer (eg: torch.optim.Adam, torch.optim.SGD)\n",
        "2. Loss Function (eg: torch.nn.CrossEntropyLoss()\n",
        "3. Tracking (Training Loss, Testing Loss, Training Accuracy, Testing Accuracy)\n",
        "\n",
        "## Hyperparameter Tuning (4%)\n",
        "\n",
        "\n",
        "* testing accuracy up to 65% or higher\n",
        "* experiment with different hyperparameters\n",
        "\n",
        "### Hyperparameters\n",
        "1. Learning Rate\n",
        "2. MLP Hidden Size\n",
        "3. Batch Size\n",
        "4. Number of Layers\n",
        "5. Number of Epochs\n",
        "\n",
        "\n",
        "### Strategies to search for the best values\n",
        "1. Random Search (Pick values randomly within a reasonable range)\n",
        "2. Grid Search (Choose a range,e.g., 0.001 to 0.01, and test values at fixed intervals)\n",
        "\n",
        "(!remove later)"
      ],
      "metadata": {
        "id": "XubiBBpcxU0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 1(c) Evaluate your model performance with testing data (2%) =====\n",
        "lr = 0.001\n",
        "epoch = 100\n",
        "\n",
        "# handle softmax\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer, adam converge faster\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "iP4AGymNFZuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 4: Report and Submission (10%)**\n",
        "## Results and Comments (6%)\n",
        "### 1. Result table\n",
        "* show testing accuracy for each different set of hyperparameters\n",
        "\n",
        "\n",
        "### 2. Commentary\n",
        "* how each hyperparameter affects performance\n",
        "* which model had the best results and list the exact hyperparameters used for it\n",
        "\n",
        "## Plots (3%)\n",
        "create two plots for best model configuration\n",
        "* Plot 1: Training Loss and Testing Loss vs. Epochs.\n",
        "* Plot 2: Training Accuracy and Testing Accuracy vs. Epochs.\n",
        "\n",
        "### Commentary:\n",
        "\n",
        "* Explain what you observe in the plots.\n",
        "* Does your model have an overfitting issue?\n",
        "\n",
        "## Formatting and Submission (1% + Others)"
      ],
      "metadata": {
        "id": "AV097WjPyvUn"
      }
    }
  ]
}